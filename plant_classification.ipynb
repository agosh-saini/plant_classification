{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2revWhZQMH_r"
      },
      "source": [
        "# Plant Classification Using Pytorch\n",
        "##### Name: Agosh Saini\n",
        "##### Website: agoshsaini.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltQ8D1ofMqAk"
      },
      "source": [
        "In this section we install kaggle and give kaggle the right permissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nrz0ZQPZlQC"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgnRC8RcM3B6"
      },
      "source": [
        "This is where we install torch and torchvision. Torch is the module used for machine learning and torchvision is geared towards image based applications. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yPgoRzOZ2zz"
      },
      "outputs": [],
      "source": [
        "! pip install torch\n",
        "! pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8NcI6gRNLds"
      },
      "source": [
        "We want to download the dataset and unzip folder. The rm -rf command is there because we want to remove the images we don't end up using. The kaggle api .json file need to be present in the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBe69yISaSJz"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download msheriey/104-flowers-garden-of-eden "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yid3JhxZbkmU"
      },
      "outputs": [],
      "source": [
        "! unzip 104-flowers-garden-of-eden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASmBaAjzg-rE"
      },
      "outputs": [],
      "source": [
        "! rm -rf jpeg-192x192/\n",
        "! rm -rf jpeg-224x224/\n",
        "! rm -rf jpeg-311x311/\n",
        "! rm 104-flowers-garden-of-eden.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwgtWzDGN2tL"
      },
      "source": [
        "Setting up the imports in this section and setting up path information. Using a gpu can speed up the training of the data a lot. We need to set up pytorch so it uses the gpu if it is available. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oKksUbZN2U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b1b98f-4617-4058-b10a-b34b39c19e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Name: Agosh Saini\n",
        "Contact: Agosh.Saini@gmail.com\n",
        "Website: agoshsaini.com\n",
        "'''\n",
        "\n",
        "\n",
        "# --- Imports --- #\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# --- path to dataset --- #\n",
        "path = 'jpeg-512x512'\n",
        "\n",
        "# --- making it work with gpu --- #\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "    \n",
        "print(\"Using - \" + str(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br9bGNGqN_jR"
      },
      "source": [
        "Tranforming images is an important part of the the image classificaiton processes. It is a way to get the model to classify \"curveball\" images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTvT62I_N_5m"
      },
      "outputs": [],
      "source": [
        "# --- randomly transform images --- #\n",
        "train_data_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomRotation(180),\n",
        "    torchvision.transforms.RandomResizedCrop(300),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.45, 0.45, 0.45], \n",
        "                                     std=[0.2, 0.2, 0.2])\n",
        "    ])\n",
        "\n",
        "test_data_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomRotation(180),\n",
        "    torchvision.transforms.RandomResizedCrop(300),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.45, 0.45, 0.45], \n",
        "                                     std=[0.2, 0.2, 0.2])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmhccCfeO6e6"
      },
      "source": [
        "Dataloaders are a great tool for managing the traing of data. They ensure all the data is interated properly while traing and validating out model. Pytorch needs the model, data, and labels being on the same device, so we are sending the data and the labels to gpu if available. Batch size controls how much data is sent through the model at a time controls the rate at which an epoch finishes. However, it can lead to a bad model if made too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm20JlowO65r"
      },
      "outputs": [],
      "source": [
        "# --- creating splits for training and testing --- #\n",
        "train_data = torchvision.datasets.ImageFolder(path + '/train', \n",
        "                                              transform=train_data_transform)\n",
        "test_data = torchvision.datasets.ImageFolder(path + '/val', \n",
        "                                             transform=test_data_transform)\n",
        "# --- dataloader information --- #\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)\n",
        "\n",
        "# --- send the data and labels to gpu if available --- #\n",
        "for inputs, labels in train_loader:\n",
        "    inputs, labels = inputs.to(device_name), labels.to(device_name)\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device_name), labels.to(device_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFwUl8hQ7RU"
      },
      "source": [
        "We are using the resnet 18 model. It has 18 layers to it and the resnet model allows for skipping of blocks. The loss fucntion and the optimizer are defined here as well. We are sending the model to the gpu if avaiable as well. Learning rate is related to the step size and the momentum is a way to overcome local minimas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPlsAJFHQ7i0"
      },
      "outputs": [],
      "source": [
        "# --- model parameters --- #\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(features, len(train_data.classes))\n",
        "\n",
        "# --- loss function and optimizer --- #\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# --- send model to gpu if available --- #\n",
        "model.to(device_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acsfUJmCaUBp"
      },
      "source": [
        "This is where we train the model. We are trying to minimize the loss function in the model. We are training for 5 passes of the dataset here which is what an epoch refers to. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeeQoGKUaUP1"
      },
      "outputs": [],
      "source": [
        "# --- training the last layer --- #\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.cuda())\n",
        "        loss = loss_func(outputs, labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.cuda().size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_data)\n",
        "    print('Epoch ' + str(epoch + 1) + ' of ' + str(epochs) + ' Loss: ' + str(epoch_loss))\n",
        "\n",
        "\n",
        "# --- saving the model --- #\n",
        "torch.save(model.state_dict(), 'flower_classifier.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUrpVyUqa7Pi"
      },
      "source": [
        "We are testing the model here using the var data in the subfloder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22srP4M0X_dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f3156b-50fc-4019-b2b1-77e81609fb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7567349137931034\n"
          ]
        }
      ],
      "source": [
        "# --- testing the model --- #\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs.cuda())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.cuda().size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(\"Accuracy: \" + str(accuracy))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}